{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import requests\n",
    "from bs4 import BeautifulSoup\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 크롤링할 웹 페이지 URL\n",
    "url = 'https://example.com'\n",
    "\n",
    "# 웹 페이지에 GET 요청을 보냄\n",
    "response = requests.get(url)\n",
    "\n",
    "# 응답이 성공적인지 확인\n",
    "if response.status_code == 200:\n",
    "    # BeautifulSoup을 사용하여 HTML 파싱\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # 원하는 데이터를 찾기 위해 HTML 요소를 선택\n",
    "    # 예를 들어, 웹 페이지의 제목을 가져오기 위해 <title> 태그를 선택\n",
    "    title = soup.find('title').text\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"웹 페이지 제목:\", title)\n",
    "else:\n",
    "    print(\"요청 실패:\", response.status_code)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, '날짜', '종가', '시가', '고가', '저가', '거래량', '변동%'], [1, '2024-03-13', '908.88', '910.55', '915.04', '884.35', '62.73M', '-1.12%'], [2, '2024-03-12', '919.13', '880.49', '919.60', '861.50', '65.44M', '7.16%'], [3, '2024-03-11', '857.74', '864.29', '887.97', '841.66', '67.84M', '-2.00%'], [4, '2024-03-08', '875.28', '951.38', '974.00', '865.06', '114.23M', '-5.55%'], [5, '2024-03-07', '926.69', '901.58', '927.67', '896.02', '58.67M', '4.47%'], [6, '2024-03-06', '887.00', '880.22', '897.24', '870.30', '57.49M', '3.18%'], [7, '2024-03-05', '859.64', '852.70', '860.97', '834.17', '51.46M', '0.85%'], [8, '2024-03-04', '852.37', '841.30', '876.95', '837.19', '60.68M', '3.60%'], [9, '2024-03-01', '822.79', '800.00', '823.00', '794.35', '47.91M', '4.00%'], [10, '2024-02-29', '791.12', '790.94', '799.90', '783.50', '49.88M', '1.87%'], [11, '2024-02-28', '776.63', '776.20', '789.33', '771.25', '37.95M', '-1.32%'], [12, '2024-02-27', '787.01', '793.81', '794.80', '771.62', '38.94M', '-0.49%'], [13, '2024-02-26', '790.92', '797.00', '806.46', '785.05', '49.90M', '0.35%'], [14, '2024-02-23', '788.17', '807.90', '823.94', '775.70', '82.94M', '0.36%'], [15, '2024-02-22', '785.38', '750.25', '785.75', '742.20', '84.53M', '16.40%'], [16, '2024-02-21', '674.72', '680.06', '688.88', '662.48', '58.24M', '-2.85%'], [17, '2024-02-20', '694.52', '719.47', '719.56', '677.34', '69.56M', '-4.35%'], [18, '2024-02-16', '726.13', '741.00', '744.02', '725.01', '49.53M', '-0.06%'], [19, '2024-02-15', '726.58', '738.69', '739.75', '724.00', '41.55M', '-1.68%'], [20, '2024-02-14', '739.00', '732.02', '742.36', '719.38', '50.08M', '2.46%'], [21, '2024-02-13', '721.28', '704.00', '734.50', '696.20', '59.78M', '-0.17%'], [22, '2024-02-12', '722.48', '726.00', '746.11', '712.50', '61.02M', '0.16%'], [23, '2024-02-09', '721.33', '705.33', '721.85', '702.12', '43.66M', '3.58%'], [24, '2024-02-08', '696.41', '700.74', '707.94', '694.55', '41.11M', '-0.65%'], [25, '2024-02-07', '700.99', '683.19', '702.20', '676.00', '48.49M', '2.75%'], [26, '2024-02-06', '682.23', '696.30', '697.54', '663.00', '68.31M', '-1.60%'], [27, '2024-02-05', '693.32', '682.25', '694.97', '672.05', '67.05M', '4.79%'], [28, '2024-02-02', '661.60', '639.74', '666.00', '636.90', '47.66M', '4.97%'], [29, '2024-02-01', '630.27', '621.00', '631.91', '616.50', '36.02M', '2.44%'], [30, '2024-01-31', '615.27', '614.40', '622.69', '607.00', '45.07M', '-1.99%'], [31, '2024-01-30', '627.74', '629.00', '634.93', '622.60', '39.60M', '0.49%'], [32, '2024-01-29', '624.65', '612.32', '624.89', '609.07', '33.90M', '2.35%'], [33, '2024-01-26', '610.31', '609.60', '617.83', '605.73', '39.03M', '-0.95%'], [34, '2024-01-25', '616.17', '623.50', '627.19', '608.50', '47.31M', '0.42%'], [35, '2024-01-24', '613.62', '603.04', '628.49', '599.38', '55.71M', '2.49%'], [36, '2024-01-23', '598.73', '595.70', '599.10', '585.85', '29.12M', '0.37%'], [37, '2024-01-22', '596.54', '600.49', '603.31', '590.70', '45.30M', '0.27%'], [38, '2024-01-19', '594.91', '579.89', '595.00', '572.25', '54.35M', '4.17%'], [39, '2024-01-18', '571.07', '572.60', '576.00', '561.07', '48.62M', '1.88%'], [40, '2024-01-17', '560.53', '563.47', '564.71', '547.40', '47.25M', '-0.58%'], [41, '2024-01-16', '563.82', '550.18', '568.35', '549.00', '44.15M', '3.06%'], [42, '2024-01-12', '547.10', '546.20', '549.70', '543.30', '35.30M', '-0.20%'], [43, '2024-01-11', '548.22', '549.99', '553.46', '535.60', '59.68M', '0.87%'], [44, '2024-01-10', '543.50', '536.16', '546.00', '534.89', '52.81M', '2.28%'], [45, '2024-01-09', '531.40', '524.01', '543.25', '516.90', '77.31M', '1.70%'], [46, '2024-01-08', '522.53', '495.12', '522.75', '494.79', '64.25M', '6.43%'], [47, '2024-01-05', '490.97', '484.62', '495.47', '483.06', '41.50M', '2.29%'], [48, '2024-01-04', '479.98', '477.67', '485.00', '475.08', '30.44M', '0.90%'], [49, '2024-01-03', '475.69', '474.85', '481.84', '473.20', '31.82M', '-1.24%'], [50, '2024-01-02', '481.68', '492.44', '492.95', '475.95', '40.84M', '-2.73%']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, newline='', encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        index = 0\n",
    "        for row in reader:\n",
    "            clean_row = [col.replace(\" \",'') for col in row]\n",
    "            clean_row = [index] + clean_row\n",
    "            data.append(clean_row)\n",
    "            index += 1\n",
    "    return data\n",
    "\n",
    "file_path = 'NVDA 과거 데이터.csv'\n",
    "\n",
    "csv_data = read_csv_file(file_path)\n",
    "print(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import list\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, tensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "# 파일 이동하며 학습하지 않으므로 path 부분 수정 필요\n",
    "\n",
    "def split_dataset(csv_path: os.PathLike, split_rate: float = 0.2) -> None:\n",
    "\n",
    "\troot_dir = os.path.dirname(csv_path)\n",
    "\n",
    "\tdf = pd.read_csv(csv_path)\n",
    "\tsize = len(df)\n",
    "\tindices = list(range(size))\n",
    "\n",
    "\t# 리스트 셔플\n",
    "\trandom.shuffle(indices)\n",
    "\n",
    "\t# train test 나눌 포인트 설정\n",
    "\tsplit_point = int(split_rate * size)\n",
    "\n",
    "\t# train test 나누기\n",
    "\ttest_ids = indices[:split_point]\n",
    "\ttrain_ids = indices[split_point:]\n",
    "\n",
    "\t# train test 정보 loc 이용하여 묶어서 csv 파일 생성\n",
    "\ttest_df = df.loc[test_ids]\n",
    "\ttest_df.to_csv(os.path.join(root_dir, 'test_answer.csv'), index=False)\n",
    "\ttrain_df = df.loc[train_ids]\n",
    "\ttrain_df.to_csv(os.path.join(root_dir, 'train_answer.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "# 건들지도 않았음 수정 필요\n",
    "\n",
    "class Cifar10Dataset(Dataset):\n",
    "    def __init__(self, image_dir,label_path, transform):    # 변수 초기화\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_dir = image_dir  # 디렉토리\n",
    "        self.labels = pd.read_csv(label_path)   # csv 파일에서 레이블 읽기\n",
    "        self.transform = transform  # ?\n",
    "\n",
    "    def __len__(self):      # Cifar10Dataset 길이 반환\n",
    "        return len(self.labels) # 레이블 길이 = 데이터셋 길이\n",
    "    \n",
    "    def __getitem__(self, index):   # Cifat10Dataset 아이템 반환\n",
    "        image_id = self.labels.loc[index]   # 레이블에서 index에 맞는 정보 묶어서 가져오기\n",
    "        image = Image.open(os.path.join(self.image_dir, f\"{image_id['id']}.png\")).convert('RGB') # RGB로 변환하여 이미지 파일 가져오기\n",
    "        label = CLASSES.index(image_id['label'])    # 레이블에 맞는 클래스명 저장\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)   # ?\n",
    "\n",
    "        return image, label # 이미지와 레이블 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# 모델 다시 만들어야 함 이미지 아니라서 컨볼루션 힘들 듯\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # 학습과 추론에 사용되는 간단한 뉴럴 네트워크\n",
    "\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # 피드 포워드 진행하는 함수\n",
    "        \n",
    "        \"\"\"\n",
    "        param x: 입력 이미지\n",
    "        type x: Tensor\n",
    "        return: 입력 이미지에 대한 예측값(클래스값)\n",
    "        rtype: Tensor\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HnV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
